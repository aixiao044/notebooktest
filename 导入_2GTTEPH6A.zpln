{
  "paragraphs": [
    {
      "text": "%spark.pyspark\n\n# create DataFrame from python list. It can infer schema for you.\ndf1 \u003d spark.createDataFrame([(1, \"andy\", 20, \"USA\"), (2, \"jeff\", 23, \"China\"), (3, \"james\", 18, \"USA\")]).toDF(\"id\", \"name\", \"age\", \"country\")\ndf1.printSchema()\ndf1.show()\ndf1.show()\n",
      "user": "admin",
      "dateUpdated": "2022-02-07 14:01:14.890",
      "progress": 0,
      "config": {
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- id: long (nullable \u003d true)\n |-- name: string (nullable \u003d true)\n |-- age: long (nullable \u003d true)\n |-- country: string (nullable \u003d true)\n\n+---+-----+---+-------+\n| id| name|age|country|\n+---+-----+---+-------+\n|  1| andy| 20|    USA|\n|  2| jeff| 23|  China|\n|  3|james| 18|    USA|\n+---+-----+---+-------+\n\n+---+-----+---+-------+\n| id| name|age|country|\n+---+-----+---+-------+\n|  1| andy| 20|    USA|\n|  2| jeff| 23|  China|\n|  3|james| 18|    USA|\n+---+-----+---+-------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://hadoop:46559/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://hadoop:46559/jobs/job?id\u003d1"
            },
            {
              "jobUrl": "http://hadoop:46559/jobs/job?id\u003d2"
            },
            {
              "jobUrl": "http://hadoop:46559/jobs/job?id\u003d3"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1642648924938_1578456329",
      "id": "20220120-112204_630923784",
      "dateCreated": "2022-01-20 11:22:04.938",
      "dateStarted": "2022-02-07 14:01:14.901",
      "dateFinished": "2022-02-07 14:02:54.778",
      "status": "FINISHED"
    },
    {
      "text": "%python\n%sql\nselect * from test\n",
      "user": "anonymous",
      "dateUpdated": "2022-01-20 11:22:04.938",
      "progress": 0,
      "config": {
        "editorMode": "ace/mode/python",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1642648924938_1321447505",
      "id": "20220120-112204_719837858",
      "dateCreated": "2022-01-20 11:22:04.938",
      "status": "READY"
    }
  ],
  "name": "导入",
  "id": "2GTTEPH6A",
  "defaultInterpreterGroup": "spark",
  "version": "0.10.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": true
  },
  "info": {}
}