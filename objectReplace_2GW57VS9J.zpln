{
  "paragraphs": [
    {
      "text": "%sql\nselect ${maxAge\u003d30}",
      "user": "admin",
      "dateUpdated": "2022-01-27 17:46:57.807",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.zeppelin.interpreter.InterpreterException: java.io.IOException: Fail to launch interpreter process:\nInterpreter download command: /usr/local/jdk1.8.0_211/bin/java -Dfile.encoding\u003dUTF-8 -Dlog4j.configuration\u003dlog4j_yarn_cluster.properties -Dzeppelin.log.file\u003d/usr/local/zeppelin/zeppelin-0.10.0-bin-all/logs/zeppelin-interpreter-spark-2GW57VS9J-root-hadoop.log -cp :/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/spark/*:::/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/zeppelin-interpreter-shaded-0.10.0.jar:/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/spark/spark-interpreter-0.10.0.jar:/usr/local/hadoop/etc/hadoop org.apache.zeppelin.interpreter.remote.RemoteInterpreterDownloader 172.16.10.176 36043 spark /usr/local/zeppelin/zeppelin-0.10.0-bin-all/local-repo/spark\nlog4j:WARN No appenders could be found for logger (org.apache.zeppelin.interpreter.remote.RemoteInterpreterDownloader).\nlog4j:WARN Please initialize the log4j system properly.\nlog4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n0    [main] INFO  org.apache.hadoop.yarn.client.RMProxy  - Connecting to ResourceManager at hadoop/172.16.10.176:8032\n279  [main] INFO  org.apache.spark.deploy.yarn.Client  - Requesting a new application from cluster with 4 NodeManagers\n888  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n960  [main] INFO  org.apache.hadoop.conf.Configuration  - resource-types.xml not found\n960  [main] INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils  - Unable to find \u0027resource-types.xml\u0027.\n984  [main] INFO  org.apache.spark.deploy.yarn.Client  - Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)\n985  [main] INFO  org.apache.spark.deploy.yarn.Client  - Will allocate AM container, with 1408 MB memory including 384 MB overhead\n985  [main] INFO  org.apache.spark.deploy.yarn.Client  - Setting up container launch context for our AM\n989  [main] INFO  org.apache.spark.deploy.yarn.Client  - Setting up the launch environment for our AM container\n1000 [main] INFO  org.apache.spark.deploy.yarn.Client  - Preparing resources for our AM container\n1112 [main] WARN  org.apache.spark.deploy.yarn.Client  - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n3742 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/tmp/spark-405613d3-706e-49ff-9685-fbe2bea4ce48/__spark_libs__2508583717243503547.zip -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/__spark_libs__2508583717243503547.zip\n26806 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/spark/spark-interpreter-0.10.0.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/spark-interpreter-0.10.0.jar\n32539 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/spark/jars/iceberg-spark3-runtime-0.12.0.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/iceberg-spark3-runtime-0.12.0.jar\n34410 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/hive/lib/iceberg-hive-runtime-0.12.0.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/iceberg-hive-runtime-0.12.0.jar\n35948 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/spark/jars/doris-spark-1.0.0-spark-3.1.2_2.12.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/doris-spark-1.0.0-spark-3.1.2_2.12.jar\n36527 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/spark/scala-2.12/spark-scala-2.12-0.10.0.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/spark-scala-2.12-0.10.0.jar\n36608 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/zeppelin-interpreter-shaded-0.10.0.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/zeppelin-interpreter-shaded-0.10.0.jar\n37974 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/zeppelin/zeppelin-0.10.0-bin-all/conf/log4j_yarn_cluster.properties -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/log4j_yarn_cluster.properties\n38033 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/spark/R/lib/sparkr.zip#sparkr -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/sparkr.zip\n38247 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/spark/python/lib/pyspark.zip -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/pyspark.zip\n38399 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/spark/python/lib/py4j-0.10.9-src.zip -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/py4j-0.10.9-src.zip\n38698 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/tmp/spark-405613d3-706e-49ff-9685-fbe2bea4ce48/__spark_conf__932594092829569200.zip -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/__spark_conf__.zip\n38890 [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: root,admin\n38891 [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: root,admin\n38891 [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: \n38892 [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: \n38893 [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, admin); groups with view permissions: Set(); users  with modify permissions: Set(root, admin); groups with modify permissions: Set()\n38962 [main] INFO  org.apache.spark.deploy.yarn.Client  - Submitting application application_1640862447206_0380 to ResourceManager\n39054 [main] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl  - Submitted application application_1640862447206_0380\n39057 [main] INFO  org.apache.spark.deploy.yarn.Client  - Application report for application_1640862447206_0380 (state: ACCEPTED)\n39061 [main] INFO  org.apache.spark.deploy.yarn.Client  - \n\t client token: N/A\n\t diagnostics: [星期四 一月 27 17:45:37 +0800 2022] Application is added to the scheduler and is not yet activated. Queue\u0027s AM resource limit exceeded.  Details : AM Partition \u003d \u003cDEFAULT_PARTITION\u003e; AM Resource Request \u003d \u003cmemory:2048, vCores:1\u003e; Queue Resource Limit for AM \u003d \u003cmemory:5120, vCores:7\u003e; User AM Resource Limit of the queue \u003d \u003cmemory:5120, vCores:7\u003e; Queue AM Resource Usage \u003d \u003cmemory:5120, vCores:3\u003e; \n\t ApplicationMaster host: N/A\n\t ApplicationMaster RPC port: -1\n\t queue: default\n\t start time: 1643276737499\n\t final status: UNDEFINED\n\t tracking URL: http://hadoop:8088/proxy/application_1640862447206_0380/\n\t user: admin\n39073 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Shutdown hook called\n39076 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Deleting directory /tmp/spark-0b958b2e-5450-4209-93a9-e2f3230c471d\n39093 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Deleting directory /tmp/spark-405613d3-706e-49ff-9685-fbe2bea4ce48\n\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.open(RemoteInterpreter.java:129)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.getFormType(RemoteInterpreter.java:271)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:440)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:71)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:182)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: Fail to launch interpreter process:\nInterpreter download command: /usr/local/jdk1.8.0_211/bin/java -Dfile.encoding\u003dUTF-8 -Dlog4j.configuration\u003dlog4j_yarn_cluster.properties -Dzeppelin.log.file\u003d/usr/local/zeppelin/zeppelin-0.10.0-bin-all/logs/zeppelin-interpreter-spark-2GW57VS9J-root-hadoop.log -cp :/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/spark/*:::/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/zeppelin-interpreter-shaded-0.10.0.jar:/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/spark/spark-interpreter-0.10.0.jar:/usr/local/hadoop/etc/hadoop org.apache.zeppelin.interpreter.remote.RemoteInterpreterDownloader 172.16.10.176 36043 spark /usr/local/zeppelin/zeppelin-0.10.0-bin-all/local-repo/spark\nlog4j:WARN No appenders could be found for logger (org.apache.zeppelin.interpreter.remote.RemoteInterpreterDownloader).\nlog4j:WARN Please initialize the log4j system properly.\nlog4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n0    [main] INFO  org.apache.hadoop.yarn.client.RMProxy  - Connecting to ResourceManager at hadoop/172.16.10.176:8032\n279  [main] INFO  org.apache.spark.deploy.yarn.Client  - Requesting a new application from cluster with 4 NodeManagers\n888  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n960  [main] INFO  org.apache.hadoop.conf.Configuration  - resource-types.xml not found\n960  [main] INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils  - Unable to find \u0027resource-types.xml\u0027.\n984  [main] INFO  org.apache.spark.deploy.yarn.Client  - Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)\n985  [main] INFO  org.apache.spark.deploy.yarn.Client  - Will allocate AM container, with 1408 MB memory including 384 MB overhead\n985  [main] INFO  org.apache.spark.deploy.yarn.Client  - Setting up container launch context for our AM\n989  [main] INFO  org.apache.spark.deploy.yarn.Client  - Setting up the launch environment for our AM container\n1000 [main] INFO  org.apache.spark.deploy.yarn.Client  - Preparing resources for our AM container\n1112 [main] WARN  org.apache.spark.deploy.yarn.Client  - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n3742 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/tmp/spark-405613d3-706e-49ff-9685-fbe2bea4ce48/__spark_libs__2508583717243503547.zip -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/__spark_libs__2508583717243503547.zip\n26806 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/spark/spark-interpreter-0.10.0.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/spark-interpreter-0.10.0.jar\n32539 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/spark/jars/iceberg-spark3-runtime-0.12.0.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/iceberg-spark3-runtime-0.12.0.jar\n34410 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/hive/lib/iceberg-hive-runtime-0.12.0.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/iceberg-hive-runtime-0.12.0.jar\n35948 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/spark/jars/doris-spark-1.0.0-spark-3.1.2_2.12.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/doris-spark-1.0.0-spark-3.1.2_2.12.jar\n36527 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/spark/scala-2.12/spark-scala-2.12-0.10.0.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/spark-scala-2.12-0.10.0.jar\n36608 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/zeppelin/zeppelin-0.10.0-bin-all/interpreter/zeppelin-interpreter-shaded-0.10.0.jar -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/zeppelin-interpreter-shaded-0.10.0.jar\n37974 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/zeppelin/zeppelin-0.10.0-bin-all/conf/log4j_yarn_cluster.properties -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/log4j_yarn_cluster.properties\n38033 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/spark/R/lib/sparkr.zip#sparkr -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/sparkr.zip\n38247 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/spark/python/lib/pyspark.zip -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/pyspark.zip\n38399 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/local/spark/python/lib/py4j-0.10.9-src.zip -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/py4j-0.10.9-src.zip\n38698 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/tmp/spark-405613d3-706e-49ff-9685-fbe2bea4ce48/__spark_conf__932594092829569200.zip -\u003e hdfs://hadoop:9820/user/admin/.sparkStaging/application_1640862447206_0380/__spark_conf__.zip\n38890 [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: root,admin\n38891 [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: root,admin\n38891 [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: \n38892 [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: \n38893 [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, admin); groups with view permissions: Set(); users  with modify permissions: Set(root, admin); groups with modify permissions: Set()\n38962 [main] INFO  org.apache.spark.deploy.yarn.Client  - Submitting application application_1640862447206_0380 to ResourceManager\n39054 [main] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl  - Submitted application application_1640862447206_0380\n39057 [main] INFO  org.apache.spark.deploy.yarn.Client  - Application report for application_1640862447206_0380 (state: ACCEPTED)\n39061 [main] INFO  org.apache.spark.deploy.yarn.Client  - \n\t client token: N/A\n\t diagnostics: [星期四 一月 27 17:45:37 +0800 2022] Application is added to the scheduler and is not yet activated. Queue\u0027s AM resource limit exceeded.  Details : AM Partition \u003d \u003cDEFAULT_PARTITION\u003e; AM Resource Request \u003d \u003cmemory:2048, vCores:1\u003e; Queue Resource Limit for AM \u003d \u003cmemory:5120, vCores:7\u003e; User AM Resource Limit of the queue \u003d \u003cmemory:5120, vCores:7\u003e; Queue AM Resource Usage \u003d \u003cmemory:5120, vCores:3\u003e; \n\t ApplicationMaster host: N/A\n\t ApplicationMaster RPC port: -1\n\t queue: default\n\t start time: 1643276737499\n\t final status: UNDEFINED\n\t tracking URL: http://hadoop:8088/proxy/application_1640862447206_0380/\n\t user: admin\n39073 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Shutdown hook called\n39076 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Deleting directory /tmp/spark-0b958b2e-5450-4209-93a9-e2f3230c471d\n39093 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Deleting directory /tmp/spark-405613d3-706e-49ff-9685-fbe2bea4ce48\n\n\tat org.apache.zeppelin.interpreter.remote.ExecRemoteInterpreterProcess.start(ExecRemoteInterpreterProcess.java:97)\n\tat org.apache.zeppelin.interpreter.ManagedInterpreterGroup.getOrCreateInterpreterProcess(ManagedInterpreterGroup.java:68)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.getOrCreateInterpreterProcess(RemoteInterpreter.java:104)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.internal_create(RemoteInterpreter.java:154)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.open(RemoteInterpreter.java:126)\n\t... 13 more\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1643276676495_1802852406",
      "id": "paragraph_1643276676495_1802852406",
      "dateCreated": "2022-01-27 17:44:36.496",
      "dateStarted": "2022-01-27 17:44:53.184",
      "dateFinished": "2022-01-27 17:45:55.092",
      "status": "ERROR"
    },
    {
      "text": "%sql\n",
      "user": "admin",
      "dateUpdated": "2022-01-27 17:44:53.182",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1643276693182_174856613",
      "id": "paragraph_1643276693182_174856613",
      "dateCreated": "2022-01-27 17:44:53.182",
      "status": "READY"
    }
  ],
  "name": "objectReplace",
  "id": "2GW57VS9J",
  "defaultInterpreterGroup": "spark",
  "version": "0.10.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": true
  },
  "info": {}
}